{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0865088",
   "metadata": {},
   "source": [
    "# Implementation of Attention\n",
    "\n",
    "In this notebook, we are going to implement several attention mechanisms from scratch using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e40a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22adea",
   "metadata": {},
   "source": [
    "Here we are implementi a simple version of attention using only dot product. The input is a sequence of vectors (for example word embeddings) and the output is a sequence of the same length where each vector is a weighted sum of all the input vectors.\n",
    "\n",
    "\n",
    "The attention mechanism allows each position to attend to all positions in the sequence, creating a weighted combination based on similarity (dot product).\n",
    "\n",
    "This simplified version does not include trainable parameters but allow us to understand the core concept of attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "414e660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" class=\"flowchart\" style=\"max-width: 569.051025390625px;\" viewBox=\"0 0 569.051025390625 894\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-svg .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-svg .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span{color:#333;}#mermaid-svg .cluster-label span p{background-color:transparent;}#mermaid-svg .label text,#mermaid-svg span{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .rough-node .label text,#mermaid-svg .node .label text,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .rough-node .label,#mermaid-svg .node .label,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg rect.text{fill:none;stroke-width:0;}#mermaid-svg .icon-shape,#mermaid-svg .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .icon-shape p,#mermaid-svg .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#mermaid-svg .icon-shape rect,#mermaid-svg .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .label-icon{display:inline-block;height:1em;overflow:visible;vertical-align:-0.125em;}#mermaid-svg .node .label-icon path{fill:currentColor;stroke:revert;stroke-width:revert;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g><marker id=\"mermaid-svg_flowchart-v2-pointEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-pointStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossEnd\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossStart\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"/><g class=\"edgePaths\"><path d=\"M283.367,77.214L259.139,82.845C234.911,88.476,186.456,99.738,162.228,108.869C138,118,138,125,138,128.5L138,132\" id=\"L_A_B_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M413.367,86L413.367,90.167C413.367,94.333,413.367,102.667,413.367,112.333C413.367,122,413.367,133,413.367,138.5L413.367,144\" id=\"L_A_C_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M138,214L138,218.167C138,222.333,138,230.667,148.409,238.764C158.817,246.862,179.635,254.724,190.043,258.656L200.452,262.587\" id=\"L_B_D_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M413.367,202L413.367,208.167C413.367,214.333,413.367,226.667,402.959,236.764C392.55,246.862,371.733,254.724,361.324,258.656L350.915,262.587\" id=\"L_C_D_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M275.684,318L275.684,322.167C275.684,326.333,275.684,334.667,275.684,342.333C275.684,350,275.684,357,275.684,360.5L275.684,364\" id=\"L_D_E_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M275.684,446L275.684,450.167C275.684,454.333,275.684,462.667,275.684,470.333C275.684,478,275.684,485,275.684,488.5L275.684,492\" id=\"L_E_F_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M275.684,550L275.684,554.167C275.684,558.333,275.684,566.667,275.684,574.333C275.684,582,275.684,589,275.684,592.5L275.684,596\" id=\"L_F_G_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M275.684,678L275.684,682.167C275.684,686.333,275.684,694.667,281.73,702.645C287.777,710.622,299.87,718.245,305.917,722.056L311.963,725.867\" id=\"L_G_H_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M503.362,86L512.977,90.167C522.592,94.333,541.821,102.667,551.436,117.5C561.051,132.333,561.051,153.667,561.051,175C561.051,196.333,561.051,217.667,561.051,237C561.051,256.333,561.051,273.667,561.051,291C561.051,308.333,561.051,325.667,561.051,345C561.051,364.333,561.051,385.667,561.051,407C561.051,428.333,561.051,449.667,561.051,469C561.051,488.333,561.051,505.667,561.051,523C561.051,540.333,561.051,557.667,561.051,577C561.051,596.333,561.051,617.667,561.051,639C561.051,660.333,561.051,681.667,541.607,697.317C522.163,712.968,483.275,722.936,463.831,727.92L444.386,732.904\" id=\"L_A_H_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M358.184,782L358.184,786.167C358.184,790.333,358.184,798.667,358.184,806.333C358.184,814,358.184,821,358.184,824.5L358.184,828\" id=\"L_H_I_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default  \" id=\"flowchart-A-0\" transform=\"translate(413.3671875, 47)\"><rect class=\"basic label-container\" style=\"\" x=\"-130\" y=\"-39\" width=\"260\" height=\"78\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -24)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Input: [Your, journey, starts, with, one, step]</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-B-1\" transform=\"translate(138, 175)\"><rect class=\"basic label-container\" style=\"fill:#ff9999 !important\" x=\"-130\" y=\"-39\" width=\"260\" height=\"78\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -24)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Select Query: journey (index 1)</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-C-3\" transform=\"translate(413.3671875, 175)\"><rect class=\"basic label-container\" style=\"\" x=\"-95.3671875\" y=\"-27\" width=\"190.734375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-65.3671875, -12)\"><rect/><foreignObject width=\"130.734375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>All tokens as Keys</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-D-5\" transform=\"translate(275.68359375, 291)\"><rect class=\"basic label-container\" style=\"\" x=\"-110.9296875\" y=\"-27\" width=\"221.859375\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-80.9296875, -12)\"><rect/><foreignObject width=\"161.859375\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Compute Dot Products</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-E-9\" transform=\"translate(275.68359375, 407)\"><rect class=\"basic label-container\" style=\"\" x=\"-130\" y=\"-39\" width=\"260\" height=\"78\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -24)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Attention Scores: [1.96, 2.79, 2.85, 1.63, 1.78, 1.72]</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-F-11\" transform=\"translate(275.68359375, 523)\"><rect class=\"basic label-container\" style=\"\" x=\"-81.578125\" y=\"-27\" width=\"163.15625\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-51.578125, -12)\"><rect/><foreignObject width=\"103.15625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Apply Softmax</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-G-13\" transform=\"translate(275.68359375, 639)\"><rect class=\"basic label-container\" style=\"\" x=\"-130\" y=\"-39\" width=\"260\" height=\"78\"/><g class=\"label\" style=\"\" transform=\"translate(-100, -24)\"><rect/><foreignObject width=\"200\" height=\"48\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table; white-space: break-spaces; line-height: 1.5; max-width: 200px; text-align: center; width: 200px;\"><span class=\"nodeLabel \"><p>Attention Weights: [0.13, 0.22, 0.24, 0.09, 0.14, 0.13]</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-H-15\" transform=\"translate(358.18359375, 755)\"><rect class=\"basic label-container\" style=\"\" x=\"-82.328125\" y=\"-27\" width=\"164.65625\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-52.328125, -12)\"><rect/><foreignObject width=\"104.65625\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Weighted Sum</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-I-19\" transform=\"translate(358.18359375, 859)\"><rect class=\"basic label-container\" style=\"fill:#99ff99 !important\" x=\"-82.4765625\" y=\"-27\" width=\"164.953125\" height=\"54\"/><g class=\"label\" style=\"\" transform=\"translate(-52.4765625, -12)\"><rect/><foreignObject width=\"104.953125\" height=\"24\"><div xmlns=\"http://www.w3.org/1999/xhtml\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"nodeLabel \"><p>Context Vector</p></span></div></foreignObject></g></g></g></g></g></svg>"
      ],
      "text/plain": [
       "<mermaid.__main__.Mermaid at 0x112e7ae40>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mermaid import Mermaid\n",
    "\n",
    "diagram = \"\"\"\n",
    "graph TD\n",
    "    A[\"Input: [Your, journey, starts, with, one, step]\"] --> B[\"Select Query: journey (index 1)\"]\n",
    "    A --> C[\"All tokens as Keys\"]\n",
    "    B --> D[\"Compute Dot Products\"]\n",
    "    C --> D\n",
    "    D --> E[\"Attention Scores: [1.96, 2.79, 2.85, 1.63, 1.78, 1.72]\"]\n",
    "    E --> F[\"Apply Softmax\"]\n",
    "    F --> G[\"Attention Weights: [0.13, 0.22, 0.24, 0.09, 0.14, 0.13]\"]\n",
    "    G --> H[\"Weighted Sum\"]\n",
    "    A --> H\n",
    "    H --> I[\"Context Vector\"]\n",
    "    \n",
    "    style B fill:#ff9999\n",
    "    style I fill:#99ff99\n",
    "\"\"\"\n",
    "\n",
    "Mermaid(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad0f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your\n",
    "     [0.55, 0.87, 0.66], # journey\n",
    "     [0.57, 0.85, 0.64], # starts\n",
    "     [0.22, 0.58, 0.33], # with\n",
    "     [0.77, 0.25, 0.10], # one\n",
    "     [0.05, 0.80, 0.55]] # step\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2d29ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "\n",
    "attention_score2 = torch.empty(inputs.shape[0])\n",
    "for i, key in enumerate(inputs):\n",
    "    attention_score2[i] = torch.dot(key, query)\n",
    "\n",
    "attention_score2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8a501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights2 = F.softmax(attention_score2, dim=0)\n",
    "attention_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a83329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, value in enumerate(inputs):\n",
    "    context_vec_2 += attention_weights2[i] * value\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e633c3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4421, 0.5931, 0.5790],\n",
       "         [0.4419, 0.6515, 0.5683],\n",
       "         [0.4431, 0.6496, 0.5671],\n",
       "         [0.4304, 0.6298, 0.5510],\n",
       "         [0.4671, 0.5910, 0.5266],\n",
       "         [0.4177, 0.6503, 0.5645]]),\n",
       " tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "         [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "         [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "         [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "         [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "         [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Dot Product Attention Mechanism\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, query):\n",
    "        \"\"\"\n",
    "        Forward pass of the attention mechanism.\n",
    "        Args:\n",
    "            query (torch.Tensor): The query tensor of shape (d_model,).\n",
    "        Returns:\n",
    "            dict: A dictionary containing the context vector and attention weights.\n",
    "        \"\"\"\n",
    "        atten_score = torch.empty((inputs.shape[0], query.shape[0]))\n",
    "        for i, key in enumerate(inputs):\n",
    "            for j, q in enumerate(query):\n",
    "                atten_score[i, j] = torch.dot(key, q)\n",
    "        atten_weights = F.softmax(atten_score, dim=-1)\n",
    "        context_vec = atten_weights @ query\n",
    "        return {\"context_vector\": context_vec, \"attention_weights\": atten_weights}\n",
    "\n",
    "\n",
    "attention = DotProductAttention()\n",
    "context_vec, atten_weights = attention(inputs).values()\n",
    "context_vec, atten_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c2340",
   "metadata": {},
   "source": [
    "Self-attention implementation \n",
    "\n",
    "This time we will implement self-attention, where the input sequence attends to itself. This is a key component of transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9856cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = x_2.shape[0]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27c64b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_q = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False) # requires_grad=True for training\n",
    "W_k = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "W_v = nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c05f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1729, -0.0048])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_2= x_2 @ W_q\n",
    "keys_2 = x_2 @ W_k\n",
    "values_2 = x_2 @ W_v\n",
    "\n",
    "query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92deb7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1823, -0.6888],\n",
       "         [-0.1142, -0.7676],\n",
       "         [-0.1443, -0.7728],\n",
       "         [ 0.0434, -0.3580],\n",
       "         [-0.6467, -0.6476],\n",
       "         [ 0.3262, -0.3395]]),\n",
       " tensor([[ 0.1196, -0.3566],\n",
       "         [ 0.4107,  0.6274],\n",
       "         [ 0.4091,  0.6390],\n",
       "         [ 0.2436,  0.4182],\n",
       "         [ 0.2653,  0.6668],\n",
       "         [ 0.2728,  0.3242]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = inputs @ W_k\n",
    "values = inputs @ W_v\n",
    "keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509a3c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1376)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score22 = query_2.dot(keys_2)\n",
    "attn_score22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af2048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2172,  0.1376,  0.1730, -0.0491,  0.7616, -0.3809])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_score2 = query_2 @ keys.T\n",
    "atten_score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717bf223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1704, 0.1611, 0.1652, 0.1412, 0.2505, 0.1117])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "\n",
    "atten_weights2 = torch.softmax(atten_score2 / d_k**0.5, dim=-1)\n",
    "atten_weights2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "126dbae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2854, 0.4081])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec2 = atten_weights2 @ values\n",
    "context_vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcad79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot Product Attention Mechanism\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "        queries = self.W_query(x)\n",
    "        atten_scores = queries @ keys.T # omega\n",
    "        atten_weights = F.softmax(atten_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        context_vectors = atten_weights @ values\n",
    "        return context_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c588836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5337, -0.1051],\n",
       "        [-0.5323, -0.1080],\n",
       "        [-0.5323, -0.1079],\n",
       "        [-0.5297, -0.1076],\n",
       "        [-0.5311, -0.1066],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "attention = ScaledDotProductAttention(d_in=3, d_out=2)\n",
    "context_vec3 = attention(inputs)\n",
    "context_vec3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093f213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
