{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14ade0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded.\n",
      "Dataset already extracted.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "\n",
    "zip_path = Path(\"sms_spam_collection.zip\")\n",
    "extract_path = Path(\"sms_spam_collection\")\n",
    "data_file = extract_path / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_extract_data(url, zip_path, extract_path):\n",
    "    if not zip_path.exists():\n",
    "        print(\"Downloading dataset...\")\n",
    "        urllib.request.urlretrieve(url, zip_path)\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "    if not extract_path.exists():\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(\"Extraction complete.\")\n",
    "    else:\n",
    "        print(\"Dataset already extracted.\")\n",
    "\n",
    "\n",
    "download_and_extract_data(url, zip_path, extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c75a5",
   "metadata": {},
   "source": [
    "# Use Spam data to fine-tune a GPT-2 model for text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7141b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435c5fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4426cdd4-55cb-42d4-ad62-70acf37cb0b7",
       "rows": [
        [
         "0",
         "ham",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "ham",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "spam",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "ham",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "ham",
         "Nah I don't think he goes to usf, he lives around here though"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = \"./sms_spam_collection/SMSSpamCollection\"\n",
    "\n",
    "df = pd.read_csv(data_file, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cc4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the dataset is imbalanced, with more \"ham\" than \"spam\" messages\n",
    "\n",
    "def balance_dataset(df):\n",
    "    spam = df[df[\"label\"] == \"spam\"]\n",
    "    ham = df[df[\"label\"] == \"ham\"].sample(n=len(spam), random_state=42)\n",
    "    balanced_df = pd.concat([spam, ham]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = balance_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9460bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8892c5fa-49cc-46ea-9a02-865a033a7ba0",
       "rows": [
        [
         "0",
         "0",
         "The evo. I just had to download flash. Jealous?"
        ],
        [
         "1",
         "0",
         "Hi Dear Call me its urgnt. I don't know whats your problem. You don't want to work or if you have any other problem at least tell me. Wating for your reply."
        ],
        [
         "2",
         "0",
         "Full heat pa:-) i have applyed oil pa."
        ],
        [
         "3",
         "0",
         "Gokila is talking with you aha:)"
        ],
        [
         "4",
         "0",
         "Dude u knw also telugu..thts gud..k, gud nyt.."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The evo. I just had to download flash. Jealous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi Dear Call me its urgnt. I don't know whats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Full heat pa:-) i have applyed oil pa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Gokila is talking with you aha:)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Dude u knw also telugu..thts gud..k, gud nyt..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0    The evo. I just had to download flash. Jealous?\n",
       "1      0  Hi Dear Call me its urgnt. I don't know whats ...\n",
       "2      0             Full heat pa:-) i have applyed oil pa.\n",
       "3      0                   Gokila is talking with you aha:)\n",
       "4      0     Dude u knw also telugu..thts gud..k, gud nyt.."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"label\"] = balanced_df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfb3af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1045, Val size: 150, Test size: 299\n"
     ]
    }
   ],
   "source": [
    "def splt_dataset(df, train_frac=0.7, val_frac=0.1):\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle the dataset\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    val_end = int(len(df) * (train_frac + val_frac))\n",
    "    train_df = df[:train_end]\n",
    "    val_df = df[train_end:val_end]\n",
    "    test_df = df[val_end:]\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = splt_dataset(balanced_df)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}, Test size: {len(test_df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a44e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"../data/sms_spam\")\n",
    "dataset_path.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(dataset_path / \"train.csv\", index=False)\n",
    "val_df.to_csv(dataset_path / \"val.csv\", index=False)\n",
    "test_df.to_csv(dataset_path / \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4186ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, dataset_path, tokenizer, max_length=None, pad_token_id=50_256):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(dataset_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"text\"].values\n",
    "        ]\n",
    "\n",
    "        self.labels = self.data[\"label\"].values\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = max(len(ids) for ids in self.encoded_texts)\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                ids[:max_length] for ids in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            ids + [pad_token_id] * (self.max_length - len(ids))\n",
    "            for ids in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_text = torch.tensor(self.encoded_texts[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return encoded_text, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107effd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 150, 299)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = SpamDataset(dataset_path / \"train.csv\", tokenizer)\n",
    "val_dataset = SpamDataset(dataset_path / \"val.csv\", tokenizer, max_length=train_dataset.max_length)\n",
    "test_dataset = SpamDataset(dataset_path / \"test.csv\", tokenizer, max_length=train_dataset.max_length)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b464bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "dl_val = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "dl_test = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651df4",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6530e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_from_papers.models import GPT2Model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "config = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_size\": 1024,\n",
    "    \"embed_dim\": 768,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_layers\": 12,\n",
    "    \"dropout\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model = GPT2Model(config)\n",
    "model.load_state_dict(torch.load(\"gpt2_124M.pth\")['model_weights'])\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a97d6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "model.lm_head = torch.nn.Linear(config[\"embed_dim\"], 2)  # 2 classes: ham and spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee457f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.transfomer_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8255b3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable parameters: 117.35M\n",
      "Trainable parameters: 7.09M\n"
     ]
    }
   ],
   "source": [
    "# count non trainable parameters\n",
    "non_trainable_params = sum(p.numel() for p in model.parameters() if not p.requires_grad)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Non-trainable parameters: {non_trainable_params / 1e6:.2f}M\")\n",
    "print(f\"Trainable parameters: {trainable_params/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 101/130 [00:09<00:02, 10.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Step 100 - Loss: 0.5670 - Examples seen: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Validation Loss: 0.7231 - Validation Accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 72/130 [00:07<00:05, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Step 200 - Loss: 0.2266 - Examples seen: 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Validation Loss: 0.5900 - Validation Accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 42/130 [00:04<00:08, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Step 300 - Loss: 0.6567 - Examples seen: 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Validation Loss: 0.3688 - Validation Accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 12/130 [00:01<00:10, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Step 400 - Loss: 0.1018 - Examples seen: 3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 112/130 [00:10<00:01, 10.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Step 500 - Loss: 0.3421 - Examples seen: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Validation Loss: 0.4604 - Validation Accuracy: 0.8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 82/130 [00:07<00:04, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Step 600 - Loss: 0.5139 - Examples seen: 4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:12<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Validation Loss: 0.3225 - Validation Accuracy: 0.8467\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, dl_train, dl_val, device, nb_epoch):\n",
    "    train_res, val_res = [], []\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    nb_examples, global_step = 0, 0\n",
    "\n",
    "    for epoch in range(nb_epoch):\n",
    "        model.train()\n",
    "        \n",
    "        for batch in tqdm(dl_train):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(inputs)  # (B, C)\n",
    "\n",
    "            # We use the logits of the last token for classification\n",
    "            logits = pred[:, -1, :]\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            nb_examples += inputs.size(0)\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1}/{nb_epoch} - Step {global_step} - Loss: {loss.item():.4f} - Examples seen: {nb_examples}\"\n",
    "                )\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dl_val):\n",
    "                inputs, labels = batch\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                pred = model(inputs)  # (B, C)\n",
    "                logits = pred[:, -1, :]\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(logits, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(dl_val)\n",
    "        val_accuracy = correct / total\n",
    "        val_res.append((val_loss, val_accuracy))\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{nb_epoch} - Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "    return train_res, val_res\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "train_res, val_res = train_model(model, optimizer, dl_train, dl_val, device, nb_epoch=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57926da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "# look at test accuracy\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in dl_test:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        pred = model(inputs)  # (B, C)\n",
    "        logits = pred[:, -1, :]\n",
    "\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a8e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_spam(text, model=model, tokenizer=tokenizer, device=device):\n",
    "\n",
    "    inputs = tokenizer.encode(text)\n",
    "    inputs = torch.tensor(inputs, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(inputs)\n",
    "        logits = pred[:, -1, :]\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        print(f\"Message: '{text}' - Predicted class: {'spam' if predicted_class == 1 else 'ham'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f15c2c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 'Hey, are we still on for lunch tomorrow?' - Predicted class: ham\n",
      "Message: 'Congratulations! You've won a $1000 Walmart gift card. Click here to claim now.' - Predicted class: spam\n"
     ]
    }
   ],
   "source": [
    "not_a_spam = \"Hey, are we still on for lunch tomorrow?\"\n",
    "spam = \"Congratulations! You've won a $1000 Walmart gift card. Click here to claim now.\"\n",
    "\n",
    "predict_spam(not_a_spam)\n",
    "predict_spam(spam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "542dcd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 'Salut, on est toujours bon pour le déjeuner demain ?' - Predicted class: spam\n",
      "Message: 'Félicitations ! Vous avez gagné une carte cadeau Walmart de 1000 $. Cliquez ici pour la réclamer maintenant.' - Predicted class: spam\n"
     ]
    }
   ],
   "source": [
    "# is it working in french?\n",
    "not_a_spam_fr = \"Salut, on est toujours bon pour le déjeuner demain ?\"\n",
    "spam_fr = \"Félicitations ! Vous avez gagné une carte cadeau Walmart de 1000 $. Cliquez ici pour la réclamer maintenant.\"\n",
    "predict_spam(not_a_spam_fr)\n",
    "predict_spam(spam_fr)\n",
    "\n",
    "# no it is not working in french. We would need to add french examples to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015dde5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
